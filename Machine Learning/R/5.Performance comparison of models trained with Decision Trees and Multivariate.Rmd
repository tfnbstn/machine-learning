---
output:
  word_document: default
  html_document: default
---
```{r}
#install.packages("e1071")
#install.packages("rattle.data")
#install.packages("rpart")
#install.packages("rpart.plot")
#install.packages("nnet")
#install.packages("caret")
#Obtaining Data:
library(rattle.data)
data=rattle.data::wine                       #The data assigned to "data".
head(data)  
```

```{r}
#Structure of The Data:
str(data)          
summary(data)
```


```{r}
#Splitting Data
set.seed(2380)                                 #to get same sample every time   
index <- sample(nrow(data),nrow(data)*0.8)     #Splitting Data
train <- data[index,]                          #assigning observations for train
test <- data[-index,]                          #assigning observations for test
table(train$Type);table(test$Type)             #displaying variable sizes
```


--------------------------DECISION TREES--------------------------------
```{r}
library(rpart)
library(rpart.plot)
model <- rpart(Type ~ ., data = data, method = "class")
rpart.plot(model)
```

```{r}
#Trainig dtM 
model_dt <- rpart(Type ~., method = "class", data = train)
#Pedtormance of the Model on Train and Test Set:
#FOR TRAIN
pred_labels_dt_train <- predict(model_dt, train, type = "class")
conf_mat_dt_train <- table(pred_labels_dt_train, train$Type)
print(c("Train:",sum(diag(conf_mat_dt_train))/sum(conf_mat_dt_train)))
#FOR TEST
pred_labels_dt_test <- predict(model_dt, test, type = "class")
conf_mat_dt_test <- table(pred_labels_dt_test, test$Type)
print(c("Test:",sum(diag(conf_mat_dt_test))/sum(conf_mat_dt_test)))
```


----------------------------------MLRM---------------------------------
```{r}
train$Type <- relevel(train$Type, ref = "1")              #Reference level were determined.
library(nnet)                                             #To use "multinom()" function.
model_mlrm <- multinom(Type ~., data = train, trace = F)  #Model generated by train data 
predicted_probs <- predict(model_mlrm,type = "probs")

#Pedtormance of the Model on Train and Test Set:
#For TRAIN
predicted_probs_train <- predict(model_mlrm, type = "probs")
predicted_class_train <- colnames(predicted_probs_train)[apply(predicted_probs_train, 1,which.max)]
conf_mat_mlr_train <- table(predicted_class_train, train$Type)
print(c("Train:",sum(diag(conf_mat_mlr_train))/sum(conf_mat_mlr_train)))
#For TEST
predicted_probs_test <- predict(model_mlrm, test, type = "probs")
predicted_class_test <- colnames(predicted_probs_test)[apply(predicted_probs_test, 1, which.max)]
conf_mat_mlr_test <- table(predicted_class_test, test$Type)
print(c("Train:",sum(diag(conf_mat_mlr_test))/sum(conf_mat_mlr_test)))
```


--------------------------VS-----------------------
```{r}
library(caret)
#DT
confusionMatrix(
factor(pred_labels_dt_test, levels = 1:3),
factor(test$Type, levels = 1:3)
)
#MLR
confusionMatrix(
factor(predicted_class_test, levels = 1:3),
factor(test$Type, levels = 1:3)
)
```






